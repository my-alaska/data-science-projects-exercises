{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd03c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e8c0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have a certain n-dimensional vector x. in our case n will equal 3 \n",
    "true_x = [100,200,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a12f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple linear function that takes ndimensional vector as it's input with parameters A and b\n",
    "def f(A,b,x):\n",
    "    return A@x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "037e4d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([510, 420, 930])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can evaluate this function on x with certain parameters\n",
    "A = np.array([[5,0,0],\n",
    "              [0,2,0],\n",
    "              [0,0,3]])\n",
    "\n",
    "b = np.array([10,20,30])\n",
    "\n",
    "true_y = f(A,b,true_x)\n",
    "\n",
    "true_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a773d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510 420 930]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([504.27767668, 423.17771858, 926.61763235])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's suppose y is a value that we can measure m times with normal measurement uncertainty and known covariance matrix\n",
    "\n",
    "m = 10\n",
    "\n",
    "S = np.array([[250,40,20],\n",
    "              [40,250,24],\n",
    "              [20,24,250]])\n",
    "\n",
    "# y_samples will serve as a set of example measurements\n",
    "y_samples = mvn.rvs(mean=true_y, cov=S, size=m,random_state = 1)\n",
    "\n",
    "print(true_y)\n",
    "y_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "034b15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's estimate the initial x value using maximum a posteriori estimate with know f function parameters(A and b)\n",
    "# and uncertainty covariance matrix\n",
    "# fortunately there's a known formula for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c91142be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_posterior(m_prior , S_prior , S_likelyhood, A, b, y):\n",
    "    # Let's calculate covariance matrix for multivariate normal posterior\n",
    "    S_posterior = inv( inv(S_prior) + A.T @ inv(S_likelyhood) @ A )\n",
    "\n",
    "    # Let's calculate mean value for multivariate normal posterior\n",
    "    m_posterior = S_posterior @ (A.T@inv(S_likelyhood)@(y-b) + inv(S_prior)@m_prior)\n",
    "    \n",
    "    return m_posterior, S_posterior\n",
    "\n",
    "def calculate_from_samples(y_samples, m_prior, S_prior, S_likelyhood, A, b, y):\n",
    "    for y in y_samples:\n",
    "            m_prior, S_prior = normal_posterior(m_prior,S_prior, S, A, b, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e18f214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98.31279399, 198.09867266, 296.58207676])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_prior = [0,0,0]\n",
    "S_prior = np.array([[400,0,0],\n",
    "                    [0,400,0],\n",
    "                    [0,0,400]])\n",
    "\n",
    "for y_ in y_samples:\n",
    "    m_prior, S_prior = normal_posterior(m_prior,S_prior, S, A, b, y_)\n",
    "    \n",
    "m_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a68c474a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98.85553534, 201.58885929, 298.87254412])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the result to regular linear transformation\n",
    "y_mean = y_samples.mean(axis=0)\n",
    "y_mean\n",
    "x_freom_mean = inv(A)@(y_mean-b)\n",
    "x_freom_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d24e5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that using multivariate normal posterior isn't a very effective option \n",
    "# as we get very similar results by simply calculating the median\n",
    "# it's just a simple exercise of bayesian statistic \n",
    "# as we're generating an 'a posteriori' distribution from 'a priori' and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda7729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
